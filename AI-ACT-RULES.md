# EU AI Act Klassifizierungsregeln

Zusammenfassung der wichtigsten Regeln zur Klassifikation von KI-Systemen nach der **EU AI Act (Verordnung (EU) 2024/1689)**.

Erstellt: 2026-01-30
Quellen: EU AI Act Regulation, classifier_logic.py, Web-Recherche

---

## ğŸ“Š Ãœberblick: Risikobasiertes System

Der EU AI Act verwendet einen **risikobasierten Ansatz** mit vier Risikoklassen:

| Risikostufe | Beschreibung | Regulierung | Strafe bei VerstoÃŸ |
|-------------|--------------|-------------|-------------------|
| ğŸš« **Unannehmbares Risiko** | Verbotene KI-Systeme | VollstÃ¤ndiges Verbot | Bis zu 35 Mio. EUR oder 7% des weltweiten Jahresumsatzes |
| âš ï¸ **Hohes Risiko** | Kritische Anwendungen | Strenge Compliance-Pflichten | Bis zu 15 Mio. EUR oder 3% des weltweiten Jahresumsatzes |
| â„¹ï¸ **Begrenztes Risiko** | Transparenz-relevante Systeme | Offenlegungspflichten | Bis zu 7,5 Mio. EUR oder 1,5% des weltweiten Jahresumsatzes |
| âœ… **Minimales Risiko** | Alle anderen KI-Systeme | Keine verpflichtenden Anforderungen | - |

---

## ğŸš« Stufe 1: Unannehmbares Risiko (Verbotene Praktiken)

**Rechtsgrundlage**: Artikel 5

Diese KI-Systeme sind **in der EU vollstÃ¤ndig verboten**, da sie Grundrechte und EU-Werte verletzen:

### Verbotene Praktiken

1. **Unterschwellige Manipulation (Art. 5(1)(a))**
   - KI-Systeme, die unterschwellige Techniken einsetzen, um das Bewusstsein zu umgehen
   - Ziel: Verhalten von Personen zu beeinflussen, das ihnen oder anderen schadet

2. **Ausnutzung von SchutzbedÃ¼rftigen (Art. 5(1)(b))**
   - Ausnutzung von SchwÃ¤chen aufgrund von Alter, Behinderung oder sozioÃ¶konomischer Lage
   - FÃ¼hrt zu Verhalten, das der Person oder anderen schadet

3. **Soziales Scoring (Art. 5(1)(c))**
   - Bewertung oder Klassifizierung von Personen basierend auf sozialem Verhalten
   - FÃ¼hrt zu nachteiliger Behandlung in nicht zusammenhÃ¤ngenden Kontexten

4. **Predictive Policing - nur Profiling (Art. 5(1)(d))**
   - Vorhersage von Straftaten **ausschlieÃŸlich** basierend auf Profiling
   - Ohne BerÃ¼cksichtigung objektiver, nachprÃ¼fbarer Fakten

5. **Gesichtserkennungs-Scraping (Art. 5(1)(e))**
   - Ungezieltes Scraping von Gesichtsbildern aus Internet oder CCTV
   - Zum Erstellen von Gesichtserkennungsdatenbanken

6. **Emotionserkennung am Arbeitsplatz/in Bildung (Art. 5(1)(f))**
   - Ableitung von Emotionen am Arbeitsplatz oder in Bildungseinrichtungen
   - **Ausnahme**: Medizinische oder sicherheitsrelevante Zwecke

7. **Biometrische Kategorisierung (sensibel) (Art. 5(1)(g))**
   - Kategorisierung durch Ableitung von:
     - Rasse oder ethnischer Herkunft
     - Politischen Meinungen
     - GewerkschaftszugehÃ¶rigkeit
     - ReligiÃ¶sen/philosophischen Ãœberzeugungen
     - Sexuellem Verhalten oder sexueller Orientierung

8. **Echtzeit-Biometrie in Ã¶ffentlichen RÃ¤umen (Art. 5(1)(h))**
   - Echtzeit-Fernidentifizierung in Ã¶ffentlich zugÃ¤nglichen RÃ¤umen
   - FÃ¼r Strafverfolgungszwecke (mit sehr engen Ausnahmen)

### Konsequenzen

- âŒ Betrieb in der EU **nicht gestattet**
- âŒ Sofortige Einstellung aller AktivitÃ¤ten erforderlich
- âš–ï¸ Strafe: Bis zu **35 Mio. EUR** oder **7% des weltweiten Jahresumsatzes**

---

## âš ï¸ Stufe 2: Hohes Risiko

**Rechtsgrundlage**: Artikel 6, Anhang I & III

Hochrisiko-KI-Systeme kÃ¶nnen Ã¼ber **zwei Wege (Pathways)** identifiziert werden:

### Pathway A: Regulierte Produkte (Anhang I)

Ein KI-System ist Hochrisiko, wenn **alle folgenden Bedingungen** erfÃ¼llt sind:

1. âœ… Das KI-System ist eine **Sicherheitskomponente** eines regulierten Produkts **ODER**
2. âœ… Das KI-System **IST selbst** ein reguliertes Produkt
3. âœ… Das Produkt erfordert eine **Drittanbieter-KonformitÃ¤tsbewertung**

**Produktkategorien (Anhang I)**:
- Medizinprodukte (Klasse IIa und hÃ¶her)
- In-vitro-Diagnostika
- Maschinen und Anlagen
- Zivilluftfahrtsysteme
- Kraftfahrzeuge und AnhÃ¤nger
- Eisenbahnsysteme
- (und weitere)

**Anwendbare Frist**: 02.08.2027

### Pathway B: Anwendungsbereiche (Anhang III)

Ein KI-System ist Hochrisiko, wenn es in einem der folgenden Bereiche eingesetzt wird:

#### 1. Biometrie (Anhang III, Nr. 1)
- Biometrische Fernidentifikation (nicht nur Verifikation)
- Biometrische Kategorisierung nach sensiblen Merkmalen
- Emotionserkennungssysteme

#### 2. Kritische Infrastruktur (Anhang III, Nr. 2)
- Sicherheitskomponenten fÃ¼r digitale Infrastruktur
- StraÃŸenverkehrsmanagement
- Wasser-/Gas-/Heizungs-/Stromversorgung

#### 3. Bildung und Berufsausbildung (Anhang III, Nr. 3)
- Zulassungsentscheidungen zu Bildungseinrichtungen
- Benotung und Bewertung von Lernenden
- VerhaltensÃ¼berwachung von SchÃ¼lern/Studenten
- PrÃ¼fungsbetrugs-Erkennung

#### 4. BeschÃ¤ftigung und Personalmanagement (Anhang III, Nr. 4)
- Rekrutierung und Lebenslauf-Screening
- Zielgerichtete Stellenanzeigen
- BewerbungsgesprÃ¤ch-Auswertung
- LeistungsÃ¼berwachung von Mitarbeitern
- BefÃ¶rderungs-/KÃ¼ndigungsentscheidungen
- Aufgabenzuweisung

#### 5. Zugang zu wesentlichen Diensten (Anhang III, Nr. 5)
- KreditwÃ¼rdigkeitsprÃ¼fung
- Risikobewertung fÃ¼r Lebens-/Krankenversicherung
- Sozialleistungs-Berechtigung
- Notruf-Bewertung und Dispatching
- Medizinische Triage

#### 6. Strafverfolgung (Anhang III, Nr. 6)
- Risikobewertung fÃ¼r (RÃ¼ck-)FÃ¤lligkeit
- Polygraph und Ã¤hnliche Werkzeuge
- Beweis-ZuverlÃ¤ssigkeitsbewertung
- Profiling bei Ermittlungen
- KriminalitÃ¤tsanalyse

#### 7. Migration und Grenzkontrolle (Anhang III, Nr. 7)
- Sicherheits-/Gesundheits-/Migrationsrisikobewertung
- Asyl-/Visa-/AufenthaltsgenehmigungsprÃ¼fung
- Dokumenten-EchtheitsprÃ¼fung
- Personenerkennung und -identifikation

#### 8. Justiz und demokratische Prozesse (Anhang III, Nr. 8)
- Rechtsrecherche und -interpretation
- Alternative Streitbeilegung
- Beweisbewertung
- Beeinflussung von Gerichtsentscheidungen

### âš ï¸ Wichtig: Ausnahmen von Hochrisiko

Ein KI-System aus Anhang III ist **NICHT hochriskant**, wenn es:

1. âœ… Nur eine **enge verfahrenstechnische Aufgabe** ausfÃ¼hrt, ODER
2. âœ… Nur das Ergebnis **bereits abgeschlossener menschlicher AktivitÃ¤t** verbessert, ODER
3. âœ… Nur **Entscheidungsmuster erkennt**, ohne menschliche Bewertung zu ersetzen, ODER
4. âœ… Nur eine **vorbereitende Aufgabe** fÃ¼r eine Bewertung ausfÃ¼hrt

**â— ABER**: Diese Ausnahmen gelten **NICHT**, wenn das System **Profiling natÃ¼rlicher Personen** durchfÃ¼hrt!

### Pflichten fÃ¼r Hochrisiko-Systeme

Anbieter mÃ¼ssen:

1. âœ… **Risikomanagementsystem** einrichten (Art. 9)
2. âœ… **Daten-Governance** sicherstellen (Art. 10)
3. âœ… **Technische Dokumentation** erstellen (Art. 11, Anhang IV)
4. âœ… **Automatische Protokollierung** implementieren (Art. 12)
5. âœ… **Transparenz** gegenÃ¼ber Betreibern gewÃ¤hrleisten (Art. 13)
6. âœ… **Menschliche Aufsicht** ermÃ¶glichen (Art. 14)
7. âœ… **Genauigkeit, Robustheit und Cybersicherheit** sicherstellen (Art. 15)
8. âœ… **KonformitÃ¤tsbewertung** durchfÃ¼hren (Art. 43)
9. âœ… **CE-Kennzeichnung** anbringen (Art. 48)
10. âœ… **Registrierung in EU-Datenbank** (Art. 49)
11. âœ… **Post-Market-Monitoring** einrichten (Art. 72)

**Anwendbare Frist**: 02.08.2026

---

## â„¹ï¸ Stufe 3: Begrenztes Risiko (Transparenzpflichten)

**Rechtsgrundlage**: Artikel 50

Diese Kategorie umfasst KI-Systeme, die **spezifische Transparenzpflichten** auslÃ¶sen, aber nicht als Hochrisiko gelten.

### Wann gelten Transparenzpflichten?

Ein KI-System unterliegt Transparenzpflichten, wenn es:

#### 1. Mit Menschen interagiert (Art. 50(1))

**Trigger**: Chatbots, virtuelle Assistenten, Konversations-KI

**Pflicht**:
- Nutzer mÃ¼ssen **darÃ¼ber informiert werden**, dass sie mit einer KI interagieren
- Ausnahme: Wenn es aus dem Kontext **offensichtlich** ist

**Beispiele**:
- Kundenservice-Chatbots
- Virtuelle Assistenten
- AI-gestÃ¼tzte Live-Chat-Systeme

#### 2. Emotionen erkennt (Art. 50(3))

**Trigger**: Emotionserkennung fÃ¼r **medizinische oder Sicherheitszwecke**

**Pflicht**:
- Betroffene Personen mÃ¼ssen Ã¼ber die Verarbeitung informiert werden
- Gilt NICHT fÃ¼r Arbeitsplatz/Bildung (das wÃ¤re verboten!)

**Beispiele**:
- Medizinische Diagnosesysteme mit Emotionserkennung
- Sicherheitssysteme zur Gefahrenerkennung

#### 3. Biometrische Kategorisierung durchfÃ¼hrt (Art. 50(3))

**Trigger**: RechtmÃ¤ÃŸige biometrische Kategorisierung (z.B. Filterung von DatensÃ¤tzen)

**Pflicht**:
- Information der betroffenen Personen
- Gilt NICHT fÃ¼r sensible Kategorien (das wÃ¤re verboten!)

#### 4. Synthetische Inhalte generiert (Art. 50(2))

**Trigger**: Generierung von Text, Audio, Bildern oder Video

**Pflicht**:
- **Maschinenlesbare Markierung** der Inhalte als KI-generiert
- Die Markierung muss:
  - âœ… Effektiv und interoperabel sein
  - âœ… Robust und zuverlÃ¤ssig sein
  - âœ… Dem Stand der Technik entsprechen

**Beispiele**:
- Text-Generatoren (GPT, Claude, etc.)
- Bild-Generatoren (DALL-E, Midjourney, Stable Diffusion)
- Video-Generatoren
- Audio/Musik-Generatoren

#### 5. Deepfakes generiert (Art. 50(4))

**Trigger**: Realistische synthetische Medien von echten Personen

**Pflicht**:
- **Offenlegungspflicht**: Inhalte mÃ¼ssen als kÃ¼nstlich erstellt/manipuliert gekennzeichnet werden
- **Ausnahmen** (nur minimale Offenlegung erforderlich):
  - Offensichtlich kÃ¼nstlerische Inhalte
  - Offensichtlich kreative Inhalte
  - Offensichtlich satirische Inhalte
  - Offensichtlich fiktionale Inhalte

**Wichtig**: Auch **rechtmÃ¤ÃŸige** Deepfakes mÃ¼ssen gekennzeichnet werden!

**Beispiele**:
- Face-Swap-Videos
- Voice-Cloning
- Realistische KI-Avatare echter Personen

### Code of Practice (Verhaltenskodex)

**Status**: Erster Entwurf verÃ¶ffentlicht am 17.12.2025

Der **Code of Practice on Transparency of AI-Generated Content** bietet praktische Anleitungen:

#### Empfohlene Kennzeichnungsmethoden:

**FÃ¼r Video**:
- Persistente visuelle Indikatoren
- ErÃ¶ffnungs-Disclaimer
- Bei Live-Video: Durchgehende Kennzeichnung

**FÃ¼r Bilder**:
- Sichtbare Labels oder Disclaimer
- Wasserzeichen
- Metadaten-Markierung

**FÃ¼r Audio**:
- HÃ¶rbare Disclaimer am Anfang
- Bei lÃ¤ngeren Inhalten: Wiederholte Hinweise

**FÃ¼r Text**:
- Gemeinsames Symbol/Icon
- Sichtbar beim ersten Kontakt
- Konsistente Platzierung

#### Zeitplan:
- **MÃ¤rz 2026**: Zweiter Entwurf erwartet
- **Juni 2026**: Finale Version erwartet
- **02.08.2026**: Artikel 50 tritt in Kraft

### Strafen bei VerstoÃŸ

âš–ï¸ Bis zu **7,5 Mio. EUR** oder **1,5% des weltweiten Jahresumsatzes**

---

## âœ… Stufe 4: Minimales Risiko

**Keine verpflichtenden Anforderungen des EU AI Act**

### Was ist Minimales Risiko?

Dies ist die **Standard-Kategorie** fÃ¼r alle KI-Systeme, die nicht in die anderen Kategorien fallen:

- âœ… Keine verbotenen Praktiken
- âœ… Kein Hochrisiko (weder Pathway A noch B)
- âœ… Keine Transparenzpflichten

**Wichtig**: Die **Ã¼berwiegende Mehrheit** aller derzeit in der EU eingesetzten KI-Systeme fÃ¤llt in diese Kategorie!

### Beispiele fÃ¼r Minimales Risiko

- **Spam-Filter** fÃ¼r E-Mails
- **Empfehlungssysteme** (Produkte, Inhalte)
- **KI-gestÃ¼tzte Videospiele**
- **Inventar-Management-Systeme**
- **Wettervorhersage-Systeme**
- **Routenplanung** (nicht fÃ¼r kritische Infrastruktur)
- **Ãœbersetzungs-Tools** (ohne Interaktion)
- **Automatische Bildoptimierung**
- **KI-gestÃ¼tzte Suchmaschinen**
- **Produktionsoptimierung** (nicht sicherheitskritisch)

### Freiwillige MaÃŸnahmen

Obwohl keine Pflichten bestehen, wird **empfohlen**:

#### 1. Freiwillige Verhaltenskodizes (Art. 95)

Die EuropÃ¤ische Kommission und die Mitgliedstaaten **ermutigen** Anbieter zur freiwilligen Anwendung von:

- âœ… Risikomanagementsystemen
- âœ… Daten-Governance-Praktiken
- âœ… TransparenzmaÃŸnahmen
- âœ… Menschlicher Aufsicht
- âœ… Genauigkeits- und Robustheitsanforderungen

**Ziel**: Best Practices auch fÃ¼r nicht-regulierte Systeme etablieren

#### 2. KI-Kompetenz (AI Literacy)

**Pflicht fÃ¼r ALLE Anbieter und Betreiber** (auch Minimal Risk!):

- âœ… Sicherstellen, dass Mitarbeiter, die mit KI-Systemen arbeiten, Ã¼ber ausreichende **KI-Kompetenz** verfÃ¼gen
- âœ… Training und Schulung bereitstellen

#### 3. DSGVO-KonformitÃ¤t

**Wichtig**: KI-Systeme unterliegen weiterhin der **DSGVO** (Datenschutz-Grundverordnung)!

- âœ… RechtmÃ¤ÃŸigkeit der Datenverarbeitung
- âœ… Zweckbindung
- âœ… Datenminimierung
- âœ… Betroffenenrechte (Auskunft, LÃ¶schung, etc.)
- âœ… Datenschutz-FolgenabschÃ¤tzung bei Bedarf

### General Purpose AI (GPAI) / Allzweck-KI

**Besondere Kategorie innerhalb von Minimal Risk**

**Definition**: KI-Modelle, die eine Vielzahl von Aufgaben ausfÃ¼hren kÃ¶nnen

**Beispiele**: GPT-4, Claude, Gemini, Llama

#### Transparenzpflichten fÃ¼r GPAI (ab 02.08.2025):

1. âœ… **Technische Dokumentation** erstellen und aktualisieren
2. âœ… **Urheberrechtliche Informationen** bereitstellen
   - Ausreichend detaillierte Zusammenfassung der fÃ¼r das Training verwendeten Inhalte
3. âœ… **Downstream-Provider** Ã¼ber Capabilities und Limitations informieren

#### GPAI mit systemischen Risiken:

Wenn das Modell besonders **leistungsfÃ¤hig** ist oder **weitverbreitet** genutzt wird:

- âœ… Modell-Evaluierungen durchfÃ¼hren
- âœ… Schwerwiegende VorfÃ¤lle verfolgen und melden
- âœ… Angemessene Cybersicherheit sicherstellen
- âœ… Energieeffizienz berÃ¼cksichtigen

#### Compliance-Nachweis:

- Anbieter kÃ¶nnen KonformitÃ¤t durch **freiwillige Verhaltenskodizes** nachweisen
- Bis harmonisierte Normen verÃ¶ffentlicht werden

### Vorteile der Freiwilligkeit

Auch ohne Pflichten kÃ¶nnen freiwillige MaÃŸnahmen:

- ğŸ¯ **Vertrauen** bei Nutzern schaffen
- ğŸ¯ **Wettbewerbsvorteile** bieten
- ğŸ¯ **Haftungsrisiken** reduzieren
- ğŸ¯ **ZukÃ¼nftige Compliance** vorbereiten (falls sich Einstufung Ã¤ndert)
- ğŸ¯ **Best Practices** der Branche etablieren

---

## ğŸ”„ Klassifizierungs-Algorithmus

### Entscheidungsbaum

```
1. PrÃ¼fung: Verbotene Praktiken (Art. 5)
   â”œâ”€ JA â†’ ğŸš« UNANNEHMBARES RISIKO
   â””â”€ NEIN â†’ Weiter zu 2.

2. PrÃ¼fung: Hochrisiko Pathway A (Anhang I)
   â”œâ”€ Sicherheitskomponente ODER Produkt selbst?
   â”‚  â”œâ”€ JA â†’ Erfordert Drittanbieter-Bewertung?
   â”‚  â”‚  â”œâ”€ JA â†’ âš ï¸ HOHES RISIKO
   â”‚  â”‚  â””â”€ NEIN â†’ Weiter zu 3.
   â”‚  â””â”€ NEIN â†’ Weiter zu 3.

3. PrÃ¼fung: Hochrisiko Pathway B (Anhang III)
   â”œâ”€ System in Hochrisiko-Bereich (Anhang III)?
   â”‚  â”œâ”€ JA â†’ Ausnahmen anwendbar?
   â”‚  â”‚  â”œâ”€ System fÃ¼hrt Profiling durch?
   â”‚  â”‚  â”‚  â”œâ”€ JA â†’ Ausnahmen NICHT anwendbar â†’ âš ï¸ HOHES RISIKO
   â”‚  â”‚  â”‚  â””â”€ NEIN â†’ PrÃ¼fe Ausnahmekriterien
   â”‚  â”‚  â”‚     â”œâ”€ Ausnahme trifft zu â†’ Weiter zu 4.
   â”‚  â”‚  â”‚     â””â”€ Ausnahme trifft NICHT zu â†’ âš ï¸ HOHES RISIKO
   â”‚  â””â”€ NEIN â†’ Weiter zu 4.

4. PrÃ¼fung: Transparenzpflichten (Art. 50)
   â”œâ”€ Interagiert mit Menschen? â†’ â„¹ï¸ BEGRENZTES RISIKO
   â”œâ”€ Generiert Deepfakes? â†’ â„¹ï¸ BEGRENZTES RISIKO
   â”œâ”€ Generiert synthetische Inhalte? â†’ â„¹ï¸ BEGRENZTES RISIKO
   â”œâ”€ Emotionserkennung (medizinisch/Sicherheit)? â†’ â„¹ï¸ BEGRENZTES RISIKO
   â”œâ”€ RechtmÃ¤ÃŸige biometrische Kategorisierung? â†’ â„¹ï¸ BEGRENZTES RISIKO
   â””â”€ Keine Trigger â†’ Weiter zu 5.

5. Standard: âœ… MINIMALES RISIKO
```

### Wichtige Hinweise zur Klassifizierung

1. **Verbotene Praktiken haben Vorrang**: Wenn auch nur eine verbotene Praktik erfÃ¼llt ist, ist das System verboten - unabhÃ¤ngig von anderen Merkmalen.

2. **Hochrisiko-Ausnahmen sind eng**: Die Ausnahmen in Anhang III gelten NUR, wenn das System KEIN Profiling durchfÃ¼hrt.

3. **Mehrfache Transparenzpflichten mÃ¶glich**: Ein System kann mehrere Transparenz-Trigger erfÃ¼llen (z.B. Chatbot + synthetische Inhalte).

4. **Dokumentationspflicht**: Anbieter, die behaupten, ein Anhang-III-System sei NICHT hochriskant, mÃ¼ssen dies dokumentieren und auf Anfrage nachweisen.

5. **GPAI ist meist Minimal Risk**: Aber mit eigenen spezifischen Transparenz- und ggf. Risikomanagement-Pflichten.

---

## ğŸ“… Zeitplan und Fristen

| Datum | Ereignis | Betroffene Systeme |
|-------|----------|-------------------|
| **01.08.2024** | AI Act tritt in Kraft | - |
| **02.02.2025** | Verbotene Praktiken gelten<br>KI-Kompetenzpflichten gelten | ğŸš« Unannehmbares Risiko<br>âœ… Alle Systeme |
| **02.08.2025** | Governance-Regeln gelten<br>GPAI-Modell-Pflichten gelten | Governance-Strukturen<br>General Purpose AI |
| **02.08.2026** | VollstÃ¤ndige Anwendung fÃ¼r Hochrisiko<br>Transparenzpflichten gelten | âš ï¸ Hohes Risiko (Anhang III)<br>â„¹ï¸ Begrenztes Risiko |
| **02.08.2027** | Hochrisiko in regulierten Produkten | âš ï¸ Hohes Risiko (Anhang I) |

---

## ğŸ“š Quellen

### Offizielle EU-Quellen
- [EU AI Act Regulation (2024/1689)](https://eur-lex.europa.eu/eli/reg/2024/1689/oj/eng)
- [Article 5: Prohibited AI Practices](https://artificialintelligenceact.eu/article/5/)
- [Article 6: Classification Rules for High-Risk AI Systems](https://artificialintelligenceact.eu/article/6/)
- [Article 50: Transparency Obligations](https://artificialintelligenceact.eu/article/50/)
- [Article 95: Codes of Conduct for Voluntary Application](https://artificialintelligenceact.eu/article/95/)
- [Annex III: High-Risk AI Systems](https://artificialintelligenceact.eu/annex/3/)

### ImplementierungsleitfÃ¤den
- [Code of Practice on marking and labelling of AI-generated content](https://digital-strategy.ec.europa.eu/en/policies/code-practice-ai-generated-content)
- [AI Act | Shaping Europe's digital future](https://digital-strategy.ec.europa.eu/en/policies/regulatory-framework-ai)
- [EU AI Act Service Desk](https://ai-act-service-desk.ec.europa.eu/)

### Analyseartikel
- [Understanding EU AI Act Risk Categories - Security Compass](https://www.securitycompass.com/blog/understanding-eu-ai-act-risk-categories/)
- [AI Risk Classification: Guide to EU AI Act Risk Categories - GDPR Local](https://gdprlocal.com/ai-risk-classification/)
- [What the EU's New AI Code of Practice Means for Labeling Deepfakes - TechPolicy.Press](https://www.techpolicy.press/what-the-eus-new-ai-code-of-practice-means-for-labeling-deepfakes/)

### Interne Quellen
- `classifier_logic.py` - Implementierung der Klassifizierungslogik

---

## âš ï¸ Haftungsausschluss

Diese Zusammenfassung dient nur zu Informationszwecken und ersetzt keine rechtliche Beratung. Die Klassifizierung basiert auf den zum Erstellungszeitpunkt (Januar 2026) verfÃ¼gbaren Informationen zum EU AI Act.

Bei Unsicherheiten oder fÃ¼r verbindliche EinschÃ¤tzungen konsultieren Sie bitte:
- Einen auf EU AI Act spezialisierten Rechtsanwalt
- Die zustÃ¤ndigen nationalen AufsichtsbehÃ¶rden
- Den offiziellen EU AI Act Service Desk

Die Regulierung entwickelt sich kontinuierlich weiter. ÃœberprÃ¼fen Sie regelmÃ¤ÃŸig auf Updates und neue Leitlinien.
